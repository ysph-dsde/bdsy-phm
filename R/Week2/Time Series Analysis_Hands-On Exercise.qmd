---
title: "Time Series Analysis"
subtitle: |
   | In Class Hands-On Exercise
   | BDSY 2025 - Public Health Modeling Project
author: "Dan Weinberger"
bibliography: references.bib
csl: nature.csl
date: 6/24/2025
date-format: long
format:
  html:
    theme: sandstone
    toc: true
    html-math-method: katex
editor: visual
highlight-style: tango
---

## Introduction

This workshop was developed by [Dr. Dan Weinberger](https://ysph.yale.edu/profile/daniel-weinberger/) from the Yale School of Public Health (YSPH) for the 12$^{th}$ International Symposium on Pneumococci and Pneumococcal Diseases (ISPPD-12) hosted in Toronto, Canada in June 2022. Here, we have adapted his workshop session #1, which compares different methods for fitting a time series dataset [@isppd_github]. Students are encouraged to explore the workshop content that Dr. Weinberger put together to learn more about the subject:

-   **GitHub:** Find the code, original data, and slides [@isppd_github].
-   **Workshop Webpage:** Find a longer description of the workshop in the format of a mini course with links to video presentations of select sections - *Workshop on the evaluation of vaccine impact* [@isppd_webpage].

The data used here is a subset of the complete set used in Oliveira, L. H. D. *et al. 2020* [@DeOliveira2021]. In their paper, national-level mortality data spanning from 2000 to 2016 for children under 5 years of age was compiled and standardized by national mortality registers in 10 Latin American and Caribbean countries. The primary cause of death was classified using the International Classification of Diseases, Tenth Revision (ICD-10) codes ([Influenza and pneumonia J09-J18](https://www.icd10data.com/ICD10CM/Codes/J00-J99/J09-J18) or Oliveira, L. H. D. *et al. 2020* Supplementary Table 2) [@DeOliveira2021_supplement; @icd10_codes]. The goal of the paper was to evaluate the efficacy of pneumococcal conjugate vaccines (PCVs) in children who received any part of the standard-of-care vaccination series.

Today, we are going to examine the efficacy of pneumococcal conjugate vaccines (PCVs) in children aged 2 to 59 months in Ecuador. The standard-of-care vaccination series involves a primary series of either two doses (administered at 2 and 4 months of age) or three doses (administered at 2, 4, and 6 months of age), with the option of an additional booster dose (administered at 12-18 months of age). This dataset does not differentiate between patients who received varying levels of inoculation, and instead reports the data if any PCV was delivered.

## Preamble

This section is drawn from Dr. Weinberger's recorded presentation *What is ‘vaccine impact’?; and Administrative data: challenges and opportunities for evaluation studies* [@isppd_video1].

Statistical inference can be reduced to quantitatively answering three types of questions:

1.  **Causation:** Was there a change, and can we identify what caused the change?
2.  **Prediction:** What do we expect to see in the future?
3.  **Certainty:** How reliable are the answers to the first two questions?

A biotechnologist developing a vaccine is primarily concerned with proving that there was a favorable change, such as mitigating the disease process in an individual. In contrast, a public health analyst aims to determine the overall impact of the vaccine on the population. For example, an effective vaccine not only protects an individual but also attenuates transmission within their immediate social circle.

This requires contextualizing the vaccine's impact as a combination of direct and indirect effects. It is important to identify and control for unexplained linear and non-linear trends unrelated to the introduction of a vaccine to a population. For example, were there changes in overall population health at the same time or changes to diagnostic methods?

We can appreciate that this is a Sisyphean task, but one that can be addressed with time series analysis. Keep in mind that the methods discussed here are most applicable to endemic diseases that are consistently present in the population, existing at a relatively stable and predictable level. The core reason is that these methods require us to have an idea of what we would expect to have seen had the vaccine not been introduced, allowing us to posit a realistic counterfactual for model evaluation.

Our study is framed by PICO. In black text are the general definitions for the acronym and in red text is the application to our example:

-   **Population:** The target population where the impact of a vaccine is to measured. [Children 2-59 months old.]{style="color: red;"}
-   **Intervention:** The date and timeframe for a vaccine intervention. [Introduction of PCV10 to the Brazilian national immunization program.]{style="color: red;"}
-   **Comparator:** Diseases or groups of diseases to compare against the intervention, which are *not* expected to be impacted by the intervention itself.
-   **Outcome:** The condition representing our expected results from the intervention. [Deaths due to pneumonia.]{style="color: red;"}

## Set Up the Environment

```{r}
#| eval: FALSE

renv::init()      # Initialize the project     
renv::restore()   # Download packages and their version saved in the lockfile
```

```{r}
#| message: FALSE
#| warning: FALSE

suppressPackageStartupMessages({
  library("readr")      # For reading in the data
  library("tibble")     # For handling tidyverse tibble data classes
  library("tidyr")      # For tidying data 
  library("dplyr")      # For data manipulation 
  library("stringr")    # For string manipulation
  library("MASS")       # Functions/datasets for statistical analysis
  library("lubridate")  # For date manipulation
  library("ggplot2")    # For creating static visualizations
  library("scales")     # For formatting plots axis
  library("gridExtra")  # Creates multiple grid-based plots
})


# Function to select "Not In"
'%!in%' <- function(x,y)!('%in%'(x,y))
```

The data has been cleaned and standardized for use here, and is imported directly using the GitHub raw URL. You can explore the additional data cleaning steps applied to all of the data in the instructor’s GitHub repository: [ysph-dsde/bdsy-phm](https://github.com/ysph-dsde/bdsy-phm). The original dataset and prior data cleaning, validation, and standardization can be found in the paper's GitHub repository and Dr. Weinberger's workshop GitHub repository [@DeOliveira2021; @isppd_github].

```{r}
#| message: FALSE
#| warning: FALSE

# Read in the cleaned data directly from the instructor's GitHub.
df <- read_csv("https://raw.githubusercontent.com/ysph-dsde/bdsy-phm/refs/heads/main/Data/ec_2to59m.csv")

# Summarize aspects and dimentions of our dataset.
glimpse(df)
```

### Data Dictionary

It is crucial that we understand the meaning of each variable in our dataset. Sometimes, there are surprising aspects embedded within the variables that are not immediately discernible from the table itself. Many sources provide a "Data Dictionary" for this purpose, but at times, you may need to interpret the variable meanings based on context and methods.

This paper did not explicitly describe each variable in a "Data Dictionary"; therefore, the following was assembled based on the context and methods provided in the paper and its supplementary materials [@DeOliveira2021; @DeOliveira2021_supplement].

-   **date:** The month when the events were recorded. This spans from `r str_c(min(df$date), " to ", max(df$date))`.

-   **country:** Specifies the country where the events were observed. This dataset only represents events recorded in Ecuador.

-   **age_group:** The age of the person who is represented in the counts. This dataset only represents infants aged 2 months to almost 5 years of age (59 months).

-   **doses:** Specifies the doses of PCV received. As described earlier, all possible combinations of the standard-of-care vaccination series and booster are represented here.

-   **J12_J18_prim:** Primary cause of death is assigned to the ICD-10 codes J12-J18. We encourage you to read more about what these [ICD-10 codes](https://www.icd10data.com/ICD10CM/Codes/J00-J99/J09-J18) represent [@DeOliveira2021_supplement; @icd10_codes].

-   **acm_noj_prim:** Primary cause of death was assigned any other ICD=10 code, excluding only the J chapter, diseases of the respiratory system.

## Initial Plot of the Time Series

We begin each time series analysis by examining the entire span of data, typically plotted as a line or scatter plot. All methods for modeling the vaccination introduction time series data require the dates when the vaccine was introduced, in this case the PCV10 vaccine.

```{r}
# Estimation when the vaccine was introduced in YYYY-MM-DD format.
vax.intro.date <- as.Date("2010-08-01")

# Date when vaccine efficacy evaluations started; at least 12 months
# following administration.
vax.eval.date <- as.Date("2011-08-01")

```

We are not going to spend time explaining how to plot using the `tidyverse` package `ggplot2()` here. Later in the week you will receive a lecture covering this topic. In the meantime, you are welcome to explore the `ggplot2` package documentation or the Data Science and Data Equity (DSDE) group's online [Book of Workshops](https://ysph-dsde.github.io/Book-of-Workshops/Data-Visualization-with-ggplot2/) [@ggplot2_doc; @book_workshops].

```{r}
#| fig.width: 8
#| fig.height: 4

p1 <- 
  ggplot(df, aes(x = date, y = J12_J18_prim)) +
      geom_line() +
      labs(title = "Deaths Categorized by\nICD-10 Codes J12-18",
         x = "Date", y = "Counts for <5 yo") +
      # Have y-axis for the two plots be the same.
      ylim(0, 250) +
      # Reference line.
      geom_vline(xintercept = vax.intro.date, col = "red", lty = 2) +
      theme_linedraw()
   

p2 <- 
  ggplot(df, aes(x = date, y = acm_noj_prim)) +
      geom_line() +
      labs(title = "Deaths Categorized by\nNon-J chapter ICD-10 Codes",
         x = "Date", y = "Counts for <5 yo") +
      # Have y-axis for the two plots be the same.
      ylim(0, 250) +
      # Reference line.
      geom_vline(xintercept = vax.intro.date, col = "red", lty = 2) +
      theme_linedraw()

# Display the plots side-by-side.
grid.arrange(p1, p2, nrow = 1)
   
```

## Simple Linear Model

To correctly fit a simple linear model to the data, we need to apply a linearization that appropriately reflects its distribution. There are more analytical approaches to achieve this that will not be covered here. We start by visually examining the distribution with a scatter plot.

::: callout-note
It is helpful to consider the data generation method, which can provide insights into the likely distribution.
:::

```{r}
#| fig.width: 6
#| fig.height: 4

p_base <- 
  ggplot(df, aes(x = date, y = J12_J18_prim)) +
      geom_point() +
      labs(title = "Deaths Scatter Plot",
         x = "Date", y = "Counts for <5 yo") +
      # Have y-axis for the two plots be the same.
      ylim(0, NA) +
      theme_linedraw()

p_base
```

Variables that reflect counts (i.e., the number of deaths per month) can be distributed as either Poisson or negative binomial. Note that Poisson regression may artificially narrow confidence intervals when the data is overdispersed. To address this, you can use a negative binomial regression or a quasipoisson model, which accounts for the unexplained variation. In this context, we will apply a negative binomial regression.

```{r}
# For modeling, we need to use an ordered, discrete variable. Simply, we 
# can use the rownames for this purpose.
df <- tibble::rownames_to_column(df, var = "index") %>%
  mutate(index = as.numeric(index))

# Apply the negative binomial regression.
mod1 <- glm.nb(J12_J18_prim ~ index , data = df)

# Examine the fitting results.
summary(mod1)
```

```{r}
#| fig.width: 6
#| fig.height: 4

# Make predictions with confidence intervals.
pred <- predict(mod1, type = "response", se.fit = TRUE)

# Add the model predictions and 95% COI to the dataframe.
df.pred <- df %>%
  mutate(se.fit = pred$se.fit, pred = pred$fit) %>%
  mutate(
    conf.low = pred - 1.96 * se.fit,
    conf.high = pred + 1.96 * se.fit
  )

# Plot the newly created model fitting.
p_sm <- p_base +
  # Add the fitting line.
  geom_line(data = df.pred, aes(x = date, y = pred),
            color = "#e41a1c") +
  # Add the confidence interval.
  geom_ribbon(data = df.pred, aes(ymin = conf.low, ymax = conf.high), 
              alpha = 0.2, fill = "blue") +
  # Change the title name.
  labs(title = "Deaths with a Negative Binomial Fit")

p_sm

```

This is not a terrible predictor of our trend, but it overlooks many known sources of variance. For instance, we know that infections have seasonal trends, sometimes referred to by its technical term periodicity. Additionally, our baseline population may change from 2005 to 2016, which can consequently shift the overall disease trend in tandem with these baseline changes.

## Building the Multiple Linear Model

::: img-float
![Principles of Seasonality - Generated with Yale's AI Clarity](Images/Principles of Seasonal Time Series.png){style="float: left; position: relative; top: 0px; padding-right: 30px; margin: auto auto auto auto;" width="450"}
:::

### Add Controls for Seasonality

Seasonality often manifests as periodicity, where recurring patterns repeat at regular, fixed intervals of time. This differs from the related concept of cyclicity, which represents recurring patterns that do not occur at regular intervals or consistently appear in regular seasons\ [@periodicity].

Each seasonal pattern can be decomposed into three components that can either remain constant (stationary) or change over time (non-stationary): mean, variance, and covariance. The figure on the left illustrates the four possible seasonal trends separately. The top-left panel shows a recurring pattern with time-invariant, stationary parameters, while the other panels demonstrate the effects of non-stationary parameters.

::: callout-note
Most time series data in the natural sciences exhibit seasonality, periodicity, or cyclicity, though these patterns may be difficult to detect when the data is noisy\ [@Ramanathan2020].
:::

To control for temporal variations such as seasonality, we employ a simple form of dynamic linear regression (DLR). Essentially, we add variables to our simple linear regression model that represents different subsections of time as new regressors. Applying a DLR allows for changes in the mean value of the underlying regression relationship\ [@Young2011]. For the regression function to recognize each date, we need to factorize the date variable to assign the month the observation occured.

```{r}
df$month <- as.factor(month(df$date))

# Inspect the first 36 entries.
df$month[1:36]

# Update the model.
mod2 <- glm.nb(J12_J18_prim ~ date + month, data = df)
summary(mod2)
```

```{r}
#| fig.width: 6
#| fig.height: 4

# Make predictions with confidence intervals.
pred2 <- predict(mod2, type = "response", se.fit = TRUE)

# Add the model predictions and 95% COI to the dataframe.
df.pred2 <- df %>%
  mutate(se.fit = pred2$se.fit, pred = pred2$fit) %>%
  mutate(
    conf.low = pred - 1.96 * se.fit,
    conf.high = pred + 1.96 * se.fit
  )

# Plot the newly created model fitting.
p_season <- p_base +
  # Add the fitting line.
  geom_line(data = df.pred2, aes(x = date, y = pred),
            color = "#e41a1c") +
  # Add the confidence interval.
  geom_ribbon(data = df.pred2, aes(ymin = conf.low, ymax = conf.high), 
              alpha = 0.2, fill = "blue") +
  # Change the title name.
  labs(title = "Deaths with a Negative Binomial Fit\nSeasonality Term Included")

p_season
```

### Add Controls for Baseline Shifts

::: img-float
![Figure by Dr. Dan Weinberger - Generated with Yale's AI Clarity \ [@isppd_video1]](Images/Principles of Offsetting.png){style="float: right; position: relative; top: 0px; padding-left: 30px; margin: auto auto auto auto;" width="450"}
:::

We can expect that the baseline population changes over time, introducing unaccounted-for heterogeneous variance to our model. In epidemiology, it is standard to contextualize raw data by applying a denominator, or offset, that represents the population at risk of the disease. 

The figure on the right illustrates how the baseline for the number of hospitalizations normalizes when we apply the population offset. Keep in mind that this ratio is often scaled to "per 100,000 persons."\ [@isppd_video1].

$$
\frac{n_{cases}}{n_{population}} \times 100,000
$$

In real-world scenarios, the total base population is not always reported, or the coverage might be unreliable for the entire span of the time series. Alternatively, we can apply denominators such as the number of people using the healthcare system, the number of people hospitalized, and similar metrics\ [@isppd_video1]. In this example, we could apply the total population size or all non-respiratory causes of mortality.

```{r}
# Create the offset using all deaths not coded as J. Transform the values
# to log before use in the negative binomial fitting.
df$log.offset <- log(df$acm_noj_prim)

# Refit the model with an offset.
model3 <- glm.nb(J12_J18_prim ~ index + month + offset(log.offset), data = df)
summary(model3)
```

```{r}
#| fig.width: 6
#| fig.height: 4

# Make predictions with confidence intervals.
pred3 <- predict(model3, type = "response", se.fit = TRUE)

# Add the model predictions and 95% COI to the dataframe.
df.pred3 <- df %>%
  mutate(se.fit = pred3$se.fit, pred = pred3$fit) %>%
  mutate(
    conf.low = pred - 1.96 * se.fit,
    conf.high = pred + 1.96 * se.fit
  )

# Plot the newly created model fitting.
p_offset <- p_base +
  # Add the fitting line.
  geom_line(data = df.pred3, aes(x = date, y = pred),
            color = "#e41a1c") +
  # Add the confidence interval.
  geom_ribbon(data = df.pred3, aes(ymin = conf.low, ymax = conf.high), 
              alpha = 0.2, fill = "blue") +
  # Change the title name.
  labs(title = "Deaths with a Negative Binomial Fit\nSeasonality Term and Offset")

p_offset
```

Notice that the seasonality trend, which was clear in the previous plot, is disrupted when the population offset is applied. Now that we have our baseline model, we are ready to proceed with examining the effect of the intervention with PCV10 after its introduction on `r vax.intro.date`.

## Does the Disease Trend or Level Change?

In this section, we will test whether the trend or level of pneumonia deaths due to pneumococcal disease changes after the introduction of the PCV10 vaccine. To accomplish this, we will set up a counterfactual model to represent what our base model predicts the death counts would have been if the vaccine had not been introduced to the population. Similarly, a factual model will be applied to represent what actually happened with the vaccine rollout.

We will then compare the factual model against the counterfactual model to determine if a difference is identified in the period following vaccine introduction. This process is generally referred to as detecting vaccine effect or vaccine impact.

:::{.callout-warning}
You want to be careful when applying causal inference methods to model building, perturbation, or prediction questions. While our analysis uses a causal framework to detect the possible impact of the vaccine introduction, this does not permit us to make definitive claims of causation.

Additionally, it is important to remember that the model we have built may have other flaws influencing its sensitivity to the pre/post vaccination period. It is always best practice to test a model under different conditions and subject it to various tests to robustly justify its accuracy, precision, and generalizability.
:::

The figure below illustrates the three phases of the vaccine rollout: pre-vaccination, post-vaccination, and a latency period between the start of vaccine distribution and efficacy evaluation. Recall that our base negative binomial model accounts for three effector variables: an ordered, discrete variable organizing the outcomes temporally without seasonality, the month to capture seasonal periodicity, and an offset to the baseline accounting for population changes. Our baseline model is expected to, and is therefore assumed to, detect the drop in average cases during the post-vaccination period.

![Figure by Dr. Dan Weinberger - From his recorded lecture _Interrupted time series analysis_\ [@isppd_video2].](Images/Vaccine Effect with Counterfactual.png){style="float: none; display: block; margin-left: auto; margin-right: auto; width: 90%;"}

This model, however, does not explicitly assign outcomes to the three phases represented in the figure. Therefore, we need to set up variables that distinguish outcomes before and after the vaccine introduction, as well as before and after the entry to the vaccine evaluation phase, in order to convert the base model into our factual and counterfactual models.

We also need to regenerate the model to produce factually-based and counterfactually-based predictions for comparison. There are three modeling approaches we will evaluate here, each employing a different method to define the pre/post and latency vaccination periods. These differences will impact our inference about vaccine effectiveness.

1.  **Interrupted Time Series with Disconnected Segments:** This method fits different line segments through the data and tests whether the slope or level of the disease changes. It can sometimes result in abrupt jumps when fitting the model.

2.  **Interrupted Time Series with Connected Segments (Spline Model):** This method allows the slope to change in the post-vaccine period but ensures the change is smooth.

3.  **Extrapolation Based on the Pre-Vaccine Period:** This method fits the model to data from the pre-vaccine period only and extrapolates the trend to the post-vaccine period.

### Method 1. Interrupted Time Series with Disconnected Segments

We will add two new binary variables to our dataset: `vax_intro` and `vax_eval`. The `vax_intro` variable will be assigned a value of `0` before `r vax.intro.date` and `1` afterward; similarly, the `vax_eval` variable will be assigned a value of `0` before `r vax.eval.date` and `1` afterward.

```{r}
# Assign outcomes to the known vaccine phases.
df <- df %>%
  mutate(
    vax_intro = ifelse(date >= vax.intro.date, 1, 0),
    vax_eval = ifelse(date >= vax.eval.date, 1, 0)
  )

# View the changes by randomly selecting dates.
df[sort(sample(1:144, 10)), c("index", "date", "vax_intro", "vax_eval")]
```

In linear modeling, it is common to include interaction terms. These terms allow the model to capture interdependencies between variables, showing how the effect of one variable on the outcome changes depending on the level of another variable. Interaction terms also enable the identification of synergistic effects, where the combined effect of two variables is greater (or less) than the sum of their individual effects.

Equation 1 shows a multiple linear regression without an interaction term, and Equation 2 shows the inclusion of the interaction term. Notice that including the interaction term impacts the slope, making it dependent on the value of the other predictor. For example, the impact of $X_1$, holding $X_2$ constant, on the slope of $Y$ is a function of $(\beta_1 + \beta_3)\ X_2$.

\begin{align}
Y &= \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \epsilon\\
Y &= \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 (X_1 \times X_2) + \epsilon
\end{align}

We will not spend more time discussing interaction terms but will briefly examine if they enhance the model's predictive power. Note that while interaction terms can improve predictive accuracy, they also complicate the model and may result in a trade-off between predictive power and generalizability to other datasets. 

First we will generate the two models, then we will evaluate their performance side-by-side.

#### No Interaction Terms

Create a simple step-change model without an interaction term involving the newly added variables, `vax_intro` and `vax_eval`.

```{r}
# Additional seasonality controls covered in the collapsed box above.
mod_method1a <- glm.nb(J12_J18_prim ~ index + month + offset(log.offset) +
                         # Change in disease during administration and 
                         # evaluation period.
                         vax_intro + vax_eval, data = df)

summary(mod_method1a)
```

```{r}
## --------------------
## Generate the factual model

# Make predictions with confidence intervals.
pred4 <- predict(mod_method1a, type = "response", se.fit = TRUE)


## --------------------
## Prepare a plot to visualize the factual model predictions

# Add the model predictions and 95% COI to the dataframe.
df.pred.its <- df %>%
  mutate(se.fit = pred4$se.fit, pred = pred4$fit) %>%
  mutate(
    conf.low = pred - 1.96 * se.fit,
    conf.high = pred + 1.96 * se.fit
  )

# Plot the newly created model fitting.
p_m1a <- p_base +
  # Add the fitting line.
  geom_line(data = df.pred.its, aes(x = date, y = pred),
            color = "#377eb8") +
  # Add the confidence interval.
  geom_ribbon(data = df.pred.its, aes(ymin = conf.low, ymax = conf.high), 
              alpha = 0.2, fill = "blue") +
  # Change the title name.
  labs(title = "Deaths with a Negative Binomial Fit\nInterupted Time Series - No Interaction Terms")


## --------------------
## Generate the counterfactual model

# Initialize the vacccine effect variables by setting them to 0.
df.counterfactual.a <- df
df.counterfactual.a$vax_intro <- 0
df.counterfactual.a$vax_eval <- 0

# Generate the fitted values using the counterfactual setup instead.
df.pred.its$pred4.cf.a <- predict(mod_method1a, type = "response", 
                                 newdata = df.counterfactual.a)


## --------------------
## Rate ratio to evaluate performance

# Generate the rate ratio between the fitted and counterfactual values.
df.pred.its$rr.its.a <- df.pred.its$pred/df.pred.its$pred4.cf.a
```

#### With Interaction Terms

Create the more complicated model option by adding an interaction term involving `vax_intro` and `vax_eval`, keeping both individually and including with an interaction with `index`.

```{r}
mod_method1b <- glm.nb(J12_J18_prim~index + month + offset(log.offset) +
                         # Add the counterfactuals with an interaction term.
                         vax_intro + vax_intro*index +
                         vax_eval + vax_eval*index, data = df)

summary(mod_method1b)
```

```{r}
## --------------------
## Generate the factual model

# Make predictions with confidence intervals.
pred5 <- predict(mod_method1b, type = "response", se.fit = TRUE)


## --------------------
## Prepare a plot to visualize the factual model predictions

# Add the model predictions and 95% COI to the dataframe.
df.pred.its <- df.pred.its %>%
  mutate(se.fit = pred5$se.fit, pred = pred4$fit) %>%
  mutate(
    conf.low = pred - 1.96 * se.fit,
    conf.high = pred + 1.96 * se.fit
  )

# Plot the newly created model fitting.
p_m1b <- p_base +
  # Add the fitting line.
  geom_line(data = df.pred.its, aes(x = date, y = pred),
            color = "#377eb8") +
  # Add the confidence interval.
  geom_ribbon(data = df.pred.its, aes(ymin = conf.low, ymax = conf.high), 
              alpha = 0.2, fill = "blue") +
  # Change the title name.
  labs(title = "Deaths with a Negative Binomial Fit\nInterupted Time Series - With Interaction Terms")


## --------------------
## Generate the counterfactual model

# Initialize the vacccine effect variables by setting them to 0.
df.counterfactual.b <- df
df.counterfactual.b$vax_intro <- 0
df.counterfactual.b$vax_eval <- 0

# Generate the fitted values using the counterfactual setup instead.
df.pred.its$pred4.cf.b <- predict(mod_method1b, type = "response", 
                                  newdata = df.counterfactual.b)


## --------------------
## Rate ratio to evaluate performance

# Generate the rate ratio between the fitted and counterfactual values.
df.pred.its$rr.its.b <- df.pred.its$pred/df.pred.its$pred4.cf.b
```


#### Compare Model Complexity

Let's start by comparing how the fit differs between the models.

```{r}
#| fig.width: 8
#| fig.height: 8

# Overlay onto plot.
p_m1a_pred <- p_m1a +
 geom_line(data = df.pred.its, aes(x = date, y = pred4.cf.a),
           color = '#e41a1c', lty = 2)

# Overlay onto plot.
p_m1b_pred <- p_m1b +
 geom_line(data = df.pred.its, aes(x = date, y = pred4.cf.b),
           color = '#e41a1c', lty = 2)

grid.arrange(p_m1a_pred, p_m1b_pred, ncol = 1)
```


We do see differences with the prediction adherance to the data we trained the model on. By qualitative examination, it appears the model with interaction terms diverge more in the post-vaccination period.

The Akaike Information Criterion (AIC) is a one measure used to compare the goodness of fit of different statistical models, while also accounting for model complexity. It helps in model selection by balancing model fit and complexity, otherwise called the bias/variance trade-off.

There are different variations of AIC, but the basic definition is

$$
\text{AIC} = 2k - 2\ln(\mathcal{L})
$$

where $k$ is the number of parameters in the model and $\mathcal{L}$ is the maximum likelihood of the model.

```{r}
AIC(mod_method1a, mod_method1b)
```

The results indicate that the AIC score is worse (higher) when interaction terms are included. Since there is no significant gain in performance, we will prefer the simpler model for better generalizability.

Below, we also observe that the interaction terms create unexpected trends in the factual/counterfactual ratio. Notably, the ratio is not 1 (indicating that factual and counterfactual predictions are the same) in the pre-vaccination period, which is not ideal.

```{r}
#| fig.width: 5
#| fig.height: 3

# Inspect methods sensitivity to vaccine impact.
p_ratio <- 
  ggplot(df.pred.its, aes(x = date, y = rr.its.a)) +
      geom_line() +
      labs(title = "Rate Ratio for the ITS Mode",
         x = "Date", y = "Rate ratio") +
      ylim(0, NA) +
      geom_vline(xintercept = vax.intro.date, col = "red", lty = 2) +
      annotate("text", x = vax.intro.date + 30, y = 00.1, label = "Vaccine Introduced", color = "red", hjust = 0) +
      theme_linedraw()

p_ratio +
  geom_line(data = df.pred.its, aes(x = date, y = rr.its.b),
            color = "#4daf4a")
  
```

:::{.callout-tip}
## Code Like a Pro
We won't try to estimate a confidence interval on the rate ratio here. Students are encouraged to checkout the the `InterventionEvaluatR` package, which will automatically calculate the confidence intervals for these ratios.
:::


### Method 2. Interrupted Time Series with Connected Segments (Spline Model)

In this case, we force the changes to be smooth so that we don't get a drastic jump after vaccination introduction that prematurly shows impact during the expected latency period. Therefore, we will add two new binary variables to our dataset: `spl1` and `spl2`. The `spl1` variable will be assigned a value of `0` before `r vax.intro.date` and `index - intro.index + 1` afterward; similarly, the `spl2` variable will be assigned a value of `0` before `r vax.eval.date` and `index - eval.index + 1` afterward.

```{r}
# Identifies the row index that represents when the vaccine was introduced
# and when the evaluation period started.
intro.index <- which(df$date == vax.intro.date)
eval.index  <- which(df$date == vax.eval.date)

# Assign outcomes to the known vaccine phases.
df <- df %>%
  mutate(
    spl1 = ifelse(index - intro.index + 1 < 0, 0, index - intro.index + 1),
    spl2 = ifelse(index - eval.index + 1 < 0, 0, index - eval.index + 1)
  )

# Inspect the changes.
df[sort(sample(1:144, 10)), c("date", "index", "spl1", "spl2")]
```

```{r}
mod4 <- glm.nb(J12_J18_prim ~ index + month + offset(log.offset) +
                 # Post-vaccine changes.
                 spl1 + spl2, data = df)

summary(mod4)
```

```{r}
## --------------------
## Generate the factual model

# Make predictions with confidence intervals.
df.pred.spl <- df %>%
  mutate(pred.spl = predict(mod4, type = "response"))


## --------------------
## Generate the counterfactual model

# Initialize the vacccine effect variables by setting them to 0.
df.counterfactual.spl <- df
df.counterfactual.spl$spl1 <- 0
df.counterfactual.spl$spl2 <- 0

# Generate the fitted values.
df.pred.spl$pred.spl.cf <- predict(mod4, type = "response", 
  # Extract fitted value and add to df.pred.
  newdata = df.counterfactual.spl)


## --------------------
## Rate ratio to evaluate performance

# Generate the rate ratio between the fitted and counterfactual values.
df.pred.spl$rr.spline <- df.pred.spl$pred.spl/df.pred.spl$pred.spl.cf
```

```{r}
#| fig.width: 6
#| fig.height: 4

## --------------------
## Prepare a plot to visualize the factual model predictions

# Make predictions with confidence intervals.
pred7 <- predict(mod4, type = "response", se.fit = TRUE)

# Add the model predictions and 95% COI to the dataframe.
df.pred.spl <- df.pred.spl %>%
  mutate(se.fit = pred7$se.fit, pred = pred7$fit) %>%
  mutate(
    conf.low = pred - 1.96 * se.fit,
    conf.high = pred + 1.96 * se.fit
  )


p7 <- 
  ggplot(df.pred.spl, aes(x = date, y = J12_J18_prim)) +
      geom_point() +
      # Add the fitted line.
      geom_line(data = df.pred.spl, aes(x = date, y = pred.spl),
                color = "#377eb8") +
      # Add the confidence interval.
      geom_ribbon(data = df.pred.spl, aes(ymin = conf.low, ymax = conf.high),
                  alpha = 0.2, fill = "blue") +
      # Add the counterfactual line.
      geom_line(data = df.pred.spl, aes(x = date, y = pred.spl.cf),
                color = "#e41a1c", lty = 2) +
      labs(title = "Deaths with a Negative Binomial Fit\nITS with Spline Smoothing",
         x = "Date", y = "Counts for <5 yo") +
      theme_linedraw() +
      # Specify aspects of the theme plot formatting settings.
      theme(panel.spacing = unit(2, 'lines'), 
            axis.text.x = element_text(angle = 90))

p7
```

We can see here that the decline follows a smoother trajectory, by design. We can check the counterfactual performace by examining the ratio again.

```{r}
#| fig.width: 5
#| fig.height: 3

# Inspect methods sensitivity to vaccine impact.
p_ratio <- p_ratio +
     geom_line(data = df.pred.spl, aes(x = date, y = rr.spline),
               color = "#4daf4a") +
      # Update the title.
      labs(title = "Rate Ratio for the ITS Mode")

p_ratio
```

### Method #3: Extrapolation Based on the Pre-Vaccine Period

First set the pneumonia variable to NA during the post-vaccine period

```{r}
df$J12_J18_prim_pre <- df$J12_J18_prim

df$J12_J18_prim_pre[which(df$date >= vax.intro.date)] <- NA

df[, c("date", "J12_J18_prim_pre")]
```

```{r}
mod5 <- glm.nb(J12_J18_prim_pre ~ index # Time trend
              + month # Seasonality
              + offset(log.offset), data = df)

# Add the prediction using the smoothed model.
df.pred.mod5 <- df %>%
  mutate(pred.mod5 = predict(mod5, type = "response", newdata = df))
```

Plot the observed and extrapolated data. Note that here the comparison is the *observed* data with the model estimate extrapolated from the pre-vaccine period. This is different form the previous models where we were just comparing the model fitted value with the model fitted value with the vaccine-effects held to 0.

```{r}
#| fig.width: 6
#| fig.height: 4

# Make predictions with confidence intervals.
pred7 <- predict(mod5, type = "response", se.fit = TRUE, newdata = df)

# Add the model predictions and 95% COI to the dataframe.
df.pred.mod5 <- df.pred.mod5 %>%
  mutate(se.fit = pred7$se.fit, pred = pred7$fit) %>%
  mutate(
    conf.low = pred - 1.96 * se.fit,
    conf.high = pred + 1.96 * se.fit
  )


p9 <- 
  ggplot(df.pred.mod5, aes(x = date, y = J12_J18_prim)) +
      geom_point() +
      # Add the fitted line.
      geom_line(data = df.pred.mod5, aes(x = date, y = pred.mod5),
                color = "#377eb8") +
      # Add the confidence interval.
      geom_ribbon(data = df.pred.mod5, aes(ymin = conf.low, ymax = conf.high),
                  alpha = 0.2, fill = "blue") +
      labs(title = "Deaths with a Negative Binomial Fit\nExtrapolating Based on the Pre-Vaccine Period",
         x = "Date", y = "Counts for <5 yo") +
      theme_linedraw() +
      # Specify aspects of the theme plot formatting settings.
      theme(panel.spacing = unit(2, 'lines'), 
            axis.text.x = element_text(angle = 90))

p9
```

Let's compare the rate ratio estimates from the 3 models.

```{r}
df.pred.mod5$rr.trend <- df$J12_J18_prim/df.pred.mod5$pred.mod5

# Inspect methods sensitivity to vaccine impact.
p_ratio <- p_ratio +
      geom_line(data = df.pred.mod5, aes(x = date, y = rr.trend),
               color = '#377eb8') +
      # Update the title.
      labs(title = "Rate Ratio for the ITS Mode")

p_ratio
```

As a rough estimate of this, let's just average the point-by-point estimates of the rate ratio during the evaluation period.

```{r}
eval.period <- df$date > vax.eval.date

rr.its.eval<- mean(df.pred.its$rr.its[eval.period])

rr.spline.eval<- mean(df.pred.spl$rr.spline[eval.period])

rr.trend.eval<- sum(df.pred.mod5$J12_J18_prim[eval.period])/sum(df.pred.mod5$pred.mod5[eval.period])

round(c('ITS'=rr.its.eval,'Spline'=rr.spline.eval,'Trend Extrapolation'=rr.trend.eval ),2)

#Percent decline
100*(1- round(c('ITS'=rr.its.eval,'Spline'=rr.spline.eval,'Trend Extrapolation'=rr.trend.eval ),2))

```

*Depending on the dataset, these 3 methods might or might not agree*

## References

::: {#refs}
:::
